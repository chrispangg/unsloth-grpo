defaults:
  - _self_
  - override hydra/launcher: joblib
  # - launcher:
  #     n_jobs: 1
  #     prefer: threads # use processes instead of threads
  #     backend: multiprocessing # use multiprocessing backend instead of loky
model:
  name: "chriswhpang/Llama-3.2-1B-Instruct-OpenThought-SFT-VLLM"
  max_seq_length: 2048
  load_in_4bit: true
  fast_inference: true
  gpu_memory_utilization: 0.4
  lora:
    rank: 64
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    alpha: 64
    use_gradient_checkpointing: "unsloth"
    random_state: 3407

training:
  learning_rate: 1e-5
  adam_beta1: 0.9
  adam_beta2: 0.99
  weight_decay: 0.1
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  optim: "adamw_8bit"
  logging_steps: 1
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 4
  num_generations: 6
  max_prompt_length: 512
  max_completion_length: 2048
  max_steps: 1000
  save_steps: 250
  max_grad_norm: 0.1
  save_total_limit: 2
  report_to: "wandb"
  output_dir: "chriswhpang/Llama-3.2-1B-Instruct-OpenThought-SFT-GRPO-GGUF"

saving:
  username: chriswhpang  # HuggingFace username
  model_dir: "Llama-3.2-1B-Instruct-OpenThought-SFT-GRPO-GGUF"
  hub_model_id: "chriswhpang/Llama-3.2-1B-Instruct-OpenThought-SFT-GRPO-GGUF"
  save_gguf:
    enabled: true
    quantization_methods:
      - "q4_k_m"
      - "q8_0"
      - "q5_k_m"
  save_merged:
    enabled: true
    methods:
      - "merged_16bit"
      - "merged_4bit"
      - "lora"
  token: ""


system_prompt: |
  Respond in the following format:
  <|begin_of_thought|>
  ...
  <|end_of_thought|>
  <|begin_of_solution|>
  ...
  <|end_of_solution|>

generation:
  temperature: 0.8
  top_p: 0.95
  max_tokens: 2048